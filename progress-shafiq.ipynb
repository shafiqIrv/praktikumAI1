{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uR1JW69eLfG_"
   },
   "source": [
    "# IF3170 Artificial Intelligence | Praktikum\n",
    "\n",
    "This notebook serves as a template for the assignment. Please create a copy of this notebook to complete your work. You can add more code blocks, markdown blocks, or new sections if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucbaI5rBLtjJ"
   },
   "source": [
    "Group Number: xx\n",
    "\n",
    "Group Members:\n",
    "- Name (NIM)\n",
    "- Name (NIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwzsfETHLfHA"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "jZJU5W_4LfHB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Import other libraries if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKbjLIdYLfHC"
   },
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "-IWFJ-gdLfHD"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdSor5sdIYGs"
   },
   "source": [
    "# 1. Exploratory Data Analysis\n",
    "\n",
    "Exploratory Data Analysis (EDA) is a crucial step in the data analysis process that involves examining and visualizing data sets to uncover patterns, trends, anomalies, and insights. It is the first step before applying more advanced statistical and machine learning techniques. EDA helps you to gain a deep understanding of the data you are working with, allowing you to make informed decisions and formulate hypotheses for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "bGiGPVYNIoWk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>N_Days</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Hepatomegaly</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>23741.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>5.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.80</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>151.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>25329.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.9</td>\n",
       "      <td>302.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>97.65</td>\n",
       "      <td>164.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15706.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>269.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4062.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23011.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>388.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>11773.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.6</td>\n",
       "      <td>346.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>122.45</td>\n",
       "      <td>90.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  N_Days             Drug      Age Sex Ascites Hepatomegaly Spiders  \\\n",
       "0   0  1170.0  D-penicillamine  23741.0   F       Y            Y       N   \n",
       "1   1  1786.0          Placebo  25329.0   F       N            Y       N   \n",
       "2   2  1067.0              NaN  15706.0   F     NaN          NaN     NaN   \n",
       "3   3  4062.0              NaN  23011.0   F     NaN          NaN     NaN   \n",
       "4   4  1067.0          Placebo  11773.0   F       N            Y       N   \n",
       "\n",
       "  Edema  Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  \\\n",
       "0     Y        5.2          NaN     2.80   108.0    1790.0  151.90   \n",
       "1     N        1.9        302.0     3.67    52.0    1866.0   97.65   \n",
       "2     N        0.6          NaN     3.73     NaN       NaN     NaN   \n",
       "3     N        0.6          NaN     3.65     NaN       NaN     NaN   \n",
       "4     N        0.6        346.0     3.80    81.0    1257.0  122.45   \n",
       "\n",
       "   Tryglicerides  Platelets  Prothrombin  Stage Status  \n",
       "0            NaN      110.0         12.4    4.0      D  \n",
       "1          164.0      329.0          9.9    2.0      C  \n",
       "2            NaN      269.0          9.8    3.0      C  \n",
       "3            NaN      388.0         11.5    4.0      C  \n",
       "4           90.0      318.0         10.9    2.0      C  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvx-gT3bLfHM"
   },
   "source": [
    "# 2. Split Training Set and Validation Set\n",
    "\n",
    "Splitting the training and validation set works as an early diagnostic towards the performance of the model we train. This is done before the preprocessing steps to **avoid data leakage inbetween the sets**. If you want to use k-fold cross-validation, split the data later and do the cleaning and preprocessing separately for each split.\n",
    "\n",
    "Note: For training, you should use the data contained in the `train.csv` given by the TA. The `test.csv` data is only used for kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4yWCUFFBLfHM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000 train + 3000 val\n",
      "15000\n"
     ]
    }
   ],
   "source": [
    "# Split training set and validation set here, store into variables train_set and val_set.\n",
    "# Remember to also keep the original training set before splitting. This will come important later.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, val_set = train_test_split(train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(len(train_set), \"train +\", len(val_set), \"val\")\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IC14lmo_LfHN"
   },
   "source": [
    "# 3. Data Cleaning and Preprocessing\n",
    "\n",
    "This step is the first thing to be done once a Data Scientist have grasped a general knowledge of the data. Raw data is **seldom ready for training**, therefore steps need to be taken to clean and format the data for the Machine Learning model to interpret.\n",
    "\n",
    "By performing data cleaning and preprocessing, you ensure that your dataset is ready for model training, leading to more accurate and reliable machine learning results. These steps are essential for transforming raw data into a format that machine learning algorithms can effectively learn from and make predictions.\n",
    "\n",
    "For each step that you will do, **please explain the reason why did you do that process. Write it in a markdown cell under the code cell you wrote.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "5rksSMAWICY_"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "temp_train = train_set\n",
    "numerical_columns = [\"Age\",\"N_Days\", \"Age\",\"Bilirubin\",\"Cholesterol\", \"Albumin\",\t\"Copper\",\t\"Alk_Phos\",\t\"SGOT\",\t\"Tryglicerides\",\t\"Platelets\",\t\"Prothrombin\"]\n",
    "categorical_columns = [\n",
    "    (\"Status\", [\"C\", \"D\"]),                  \n",
    "    (\"Drug\", [\"D-penicillamine\", \"Placebo\"]), \n",
    "    (\"Sex\", [\"M\", \"F\"]),                    \n",
    "    (\"Ascites\", [\"N\", \"Y\"]),                \n",
    "    (\"Hepatomegaly\", [\"N\", \"Y\"]),           \n",
    "    (\"Spiders\", [\"N\", \"Y\"]),                \n",
    "    (\"Edema\", [\"N\", \"S\", \"Y\"]),       \n",
    "    (\"Stage\", [1, 2, 3, 4])              \n",
    "]\n",
    "\n",
    "\n",
    "# Handle data cleaning and Preprocessing here\n",
    "# Handle Missing values\n",
    "def handleMissingValues(data):\n",
    "    for column in data.columns:\n",
    "        if column in numerical_columns: \n",
    "            # Diisi deng\n",
    "            data[column].fillna(data[column].mean(), inplace=True)\n",
    "        else:  \n",
    "            # Diisi berdasarkan mayoritas buat kategorikal\n",
    "            data[column].fillna(data[column].mode(), inplace=True)\n",
    "    print(f\"Number of rows: {len(data)}\")\n",
    "    return data\n",
    "# Handle Outliers\n",
    "def handleOutliers(data):\n",
    "    for column in numerical_columns:\n",
    "        Q1 = data[column].quantile(0.25)\n",
    "        Q3 = data[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        data[column] = data[column].clip(lower_bound, upper_bound)\n",
    "\n",
    "    for col_name, valid_values in categorical_columns:\n",
    "        if col_name in data.columns:\n",
    "            # Replace invalid values with NaN\n",
    "            data[col_name] = data[col_name].apply(\n",
    "                lambda x: x if x in valid_values else np.nan\n",
    "            )\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ctVzt5DLfHd"
   },
   "source": [
    "# 3. Compile Preprocessing Pipeline\n",
    "\n",
    "All of the preprocessing classes or functions defined earlier will be compiled in this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_ZlncSVjJG6"
   },
   "source": [
    "If you use sklearn to create preprocessing classes, you can list your preprocessing classes in the Pipeline object sequentially, and then fit and transform your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHraoW_7LfHd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shafi\\AppData\\Local\\Temp\\ipykernel_78204\\104476672.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].fillna(data[column].mode()[0], inplace=True)\n",
      "C:\\Users\\Shafi\\AppData\\Local\\Temp\\ipykernel_78204\\104476672.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].fillna(data[column].mean(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>N_Days</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Hepatomegaly</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9839</th>\n",
       "      <td>9839</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>14019.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2.10</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>3.69</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1637.000000</td>\n",
       "      <td>136.411582</td>\n",
       "      <td>96.273327</td>\n",
       "      <td>136.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9680</th>\n",
       "      <td>9680</td>\n",
       "      <td>4190.0</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>14060.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.90</td>\n",
       "      <td>263.008434</td>\n",
       "      <td>3.50</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>63.753051</td>\n",
       "      <td>119.544455</td>\n",
       "      <td>213.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7093</th>\n",
       "      <td>7093</td>\n",
       "      <td>2812.0</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>18302.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.70</td>\n",
       "      <td>321.327710</td>\n",
       "      <td>3.48</td>\n",
       "      <td>76.178271</td>\n",
       "      <td>1670.811899</td>\n",
       "      <td>109.164633</td>\n",
       "      <td>110.817782</td>\n",
       "      <td>273.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11293</th>\n",
       "      <td>11293</td>\n",
       "      <td>3149.0</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>20459.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.90</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>3.65</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>71.300000</td>\n",
       "      <td>96.273327</td>\n",
       "      <td>311.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>820</td>\n",
       "      <td>460.0</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>23241.0</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.90</td>\n",
       "      <td>356.319276</td>\n",
       "      <td>3.90</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>645.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>96.273327</td>\n",
       "      <td>228.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>5191</td>\n",
       "      <td>2716.0</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>19358.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.60</td>\n",
       "      <td>321.327710</td>\n",
       "      <td>3.58</td>\n",
       "      <td>76.178271</td>\n",
       "      <td>1670.811899</td>\n",
       "      <td>109.164633</td>\n",
       "      <td>110.817782</td>\n",
       "      <td>330.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13418</th>\n",
       "      <td>13418</td>\n",
       "      <td>625.0</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>23741.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>3.45</td>\n",
       "      <td>321.327710</td>\n",
       "      <td>3.40</td>\n",
       "      <td>76.178271</td>\n",
       "      <td>1670.811899</td>\n",
       "      <td>109.164633</td>\n",
       "      <td>110.817782</td>\n",
       "      <td>190.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>5390</td>\n",
       "      <td>2534.0</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>21185.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.60</td>\n",
       "      <td>321.327710</td>\n",
       "      <td>3.45</td>\n",
       "      <td>76.178271</td>\n",
       "      <td>1670.811899</td>\n",
       "      <td>109.164633</td>\n",
       "      <td>110.817782</td>\n",
       "      <td>200.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>860</td>\n",
       "      <td>2456.0</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>17774.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.40</td>\n",
       "      <td>263.008434</td>\n",
       "      <td>3.60</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1009.000000</td>\n",
       "      <td>136.411582</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>271.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>7270</td>\n",
       "      <td>4190.0</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>14060.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.70</td>\n",
       "      <td>263.008434</td>\n",
       "      <td>3.60</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>642.000000</td>\n",
       "      <td>106.950000</td>\n",
       "      <td>96.273327</td>\n",
       "      <td>128.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  N_Days             Drug      Age Sex Ascites Hepatomegaly  \\\n",
       "9839    9839  1967.0  D-penicillamine  14019.0   F       N            Y   \n",
       "9680    9680  4190.0          Placebo  14060.0   F       N            N   \n",
       "7093    7093  2812.0  D-penicillamine  18302.0   F       N            N   \n",
       "11293  11293  3149.0  D-penicillamine  20459.0   F       N            N   \n",
       "820      820   460.0  D-penicillamine  23241.0   M       N            N   \n",
       "...      ...     ...              ...      ...  ..     ...          ...   \n",
       "5191    5191  2716.0  D-penicillamine  19358.0   F       N            N   \n",
       "13418  13418   625.0  D-penicillamine  23741.0   F       N            N   \n",
       "5390    5390  2534.0  D-penicillamine  21185.0   F       N            N   \n",
       "860      860  2456.0  D-penicillamine  17774.0   F       N            N   \n",
       "7270    7270  4190.0  D-penicillamine  14060.0   F       N            N   \n",
       "\n",
       "      Spiders Edema  Bilirubin  Cholesterol  Albumin     Copper     Alk_Phos  \\\n",
       "9839        N     N       2.10   315.000000     3.69  75.000000  1637.000000   \n",
       "9680        N     N       0.90   263.008434     3.50  24.000000   423.000000   \n",
       "7093        N     N       0.70   321.327710     3.48  76.178271  1670.811899   \n",
       "11293       N     N       0.90   298.000000     3.65  25.000000   685.000000   \n",
       "820         N     N       0.90   356.319276     3.90  39.000000   645.000000   \n",
       "...       ...   ...        ...          ...      ...        ...          ...   \n",
       "5191        N     N       0.60   321.327710     3.58  76.178271  1670.811899   \n",
       "13418       N     N       3.45   321.327710     3.40  76.178271  1670.811899   \n",
       "5390        N     N       0.60   321.327710     3.45  76.178271  1670.811899   \n",
       "860         N     N       1.40   263.008434     3.60  74.000000  1009.000000   \n",
       "7270        N     N       0.70   263.008434     3.60  63.000000   642.000000   \n",
       "\n",
       "             SGOT  Tryglicerides  Platelets  Prothrombin  Stage Status  \n",
       "9839   136.411582      96.273327      136.0          9.6    3.0      C  \n",
       "9680    63.753051     119.544455      213.0         10.1    2.0      C  \n",
       "7093   109.164633     110.817782      273.0         10.6    3.0      C  \n",
       "11293   71.300000      96.273327      311.0          9.7    3.0      C  \n",
       "820     70.000000      96.273327      228.0         12.3    3.0      D  \n",
       "...           ...            ...        ...          ...    ...    ...  \n",
       "5191   109.164633     110.817782      330.0          9.9    3.0      C  \n",
       "13418  109.164633     110.817782      190.0         11.0    4.0      D  \n",
       "5390   109.164633     110.817782      200.0         10.3    4.0      C  \n",
       "860    136.411582     108.000000      271.0         10.1    3.0      C  \n",
       "7270   106.950000      96.273327      128.0         10.5    3.0      C  \n",
       "\n",
       "[12000 rows x 20 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class HandleMissingValues(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        data = X.copy()\n",
    "        for column in data.columns:\n",
    "            if column in numerical_columns: \n",
    "                data[column].fillna(data[column].mean(), inplace=True)\n",
    "            else:  \n",
    "                data[column].fillna(data[column].mode()[0], inplace=True)\n",
    "        return data\n",
    "\n",
    "class HandleOutliers(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        data = X.copy()\n",
    "        for column in numerical_columns:\n",
    "            Q1 = data[column].quantile(0.25)\n",
    "            Q3 = data[column].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            data[column] = data[column].clip(lower_bound, upper_bound)\n",
    "        \n",
    "        for col_name, valid_values in categorical_columns:\n",
    "            if col_name in data.columns:\n",
    "                data[col_name] = data[col_name].apply(\n",
    "                    lambda x: x if x in valid_values else np.nan\n",
    "                )\n",
    "        return data\n",
    "\n",
    "pipe = Pipeline([(\"imputer\", HandleMissingValues()),\n",
    "                 (\"outlier_remover\", HandleOutliers())])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9s56aFFxLfHd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shafi\\AppData\\Local\\Temp\\ipykernel_78204\\104476672.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].fillna(data[column].mode()[0], inplace=True)\n",
      "C:\\Users\\Shafi\\AppData\\Local\\Temp\\ipykernel_78204\\104476672.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].fillna(data[column].mean(), inplace=True)\n",
      "C:\\Users\\Shafi\\AppData\\Local\\Temp\\ipykernel_78204\\104476672.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].fillna(data[column].mode()[0], inplace=True)\n",
      "C:\\Users\\Shafi\\AppData\\Local\\Temp\\ipykernel_78204\\104476672.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[column].fillna(data[column].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# # Your code should work up until this point\n",
    "train_set = pipe.fit_transform(train_set)\n",
    "val_set = pipe.transform(val_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXoCqMztjhr-"
   },
   "source": [
    "or create your own here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7OoZ3oXEj2CW"
   },
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9A3adbZXLfHe"
   },
   "source": [
    "# 4. Modeling and Validation\n",
    "\n",
    "Modelling is the process of building your own machine learning models to solve specific problems, or in this assignment context, predicting the probability for each class in the `Status` feature (`Status_C`, `Status_CL`, `Status_D`). Validation is the process of evaluating your trained model using the validation set or cross-validation method and providing some metrics that can help you decide what to do in the next iteration of development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnhMNbBILfHf"
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KV6ICmFmlqjk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nW0bMzkDLfHf"
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_XwsN_-LfHg"
   },
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLDtIkPdLfHg"
   },
   "source": [
    "## ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZ6_x1LKLfHh"
   },
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iP4TQDeRUUE0"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIjExgsPUYmM"
   },
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pg8aMBvoUWM-"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0E70wbTkUV58"
   },
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoH2u6fOLfHh"
   },
   "source": [
    "## Notes for improvements\n",
    "\n",
    "- **Visualize the model evaluation result**\n",
    "\n",
    "This will help you to understand the details more clearly about your model's performance. From the visualization, you can see clearly if your model is leaning towards a class than the others. (Hint: confusion matrix, ROC-AUC curve, etc.)\n",
    "\n",
    "- **Explore the hyperparameters of your models**\n",
    "\n",
    "Each models have their own hyperparameters. And each of the hyperparameter have different effects on the model behaviour. You can optimize the model performance by finding the good set of hyperparameters through a process called **hyperparameter tuning**. (Hint: Grid search, random search, bayesian optimization)\n",
    "\n",
    "- **Cross-validation**\n",
    "\n",
    "Cross-validation is a critical technique in machine learning and data science for evaluating and validating the performance of predictive models. It provides a more **robust** and **reliable** evaluation method compared to a hold-out (single train-test set) validation. Though, it requires more time and computing power because of how cross-validation works. (Hint: k-fold cross-validation, stratified k-fold cross-validation, etc.)\n",
    "\n",
    "- **Ensemble methods**\n",
    "\n",
    "Ensemble methods are powerful machine learning techniques that combine the predictions of multiple models (often referred to as base learners or weak learners) to create a stronger, more accurate predictive model. The idea behind ensemble methods is that by aggregating the opinions of multiple models, you can reduce the impact of individual model errors and improve overall prediction performance. (Hint: bagging, boosting, stacking, voting)\n",
    "\n",
    "- **Model interpretation**\n",
    "\n",
    "Model interpretation is the process of understanding and explaining the inner workings of a machine learning model, particularly its decision-making process. Interpretation helps data scientists, stakeholders, and end-users gain insights into why a model makes certain predictions or classifications. Model interpretation is crucial for building trust in machine learning systems, identifying biases, and extracting actionable information from models. (Hint: Feature importance, PDP, SHAP Values, etc)\n",
    "\n",
    "- **Explore other models**\n",
    "\n",
    "There are a lot of ML models that you can use in this usecase. Try to explore and use them to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Li4l53DjLfHh"
   },
   "source": [
    "## Submission\n",
    "To predict the test set target feature and submit the results to the kaggle competition platform, do the following:\n",
    "1. Create a new pipeline instance identical to the first in Data Preprocessing\n",
    "2. With the pipeline, apply `fit_transform` to the original training set before splitting, then only apply `transform` to the test set.\n",
    "3. Retrain the model on the preprocessed training set\n",
    "4. Predict the test set\n",
    "5. Make sure the submission contains the `id`, `Status_C`, `Status_CL`, `Status_D` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LeqnfWc-LfHi"
   },
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-jXvKOpLfHi"
   },
   "source": [
    "# 6. Error Analysis\n",
    "\n",
    "Based on all the process you have done until the modeling and evaluation step, write an analysis to support each steps you have taken to solve this problem. Write the analysis using the markdown block. Some questions that may help you in writing the analysis:\n",
    "\n",
    "- Does my model perform better in predicting one class than the other? If so, why is that?\n",
    "- To each models I have tried, which performs the best and what could be the reason?\n",
    "- Is it better for me to impute or drop the missing data? Why?\n",
    "- Does feature scaling help improve my model performance?\n",
    "- etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWL3nEAELfHj"
   },
   "source": [
    "`Provide your analysis here`"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
